!!!!!!!!!!!!In words, if the standard deviation of the series is proportional to the level of the series,then transforming to logarithms will produce a series with approximately constant variance over time.(TSA P98)

申购赎回与其他特征的关系：先判别再回归

识别不活跃用户

!!!!!!对用户聚类!!!!!!!!!!!!!!!!!!!!!!!!!

！！！！分敏感用户和不敏感用户

！！！30天外推太多了，只考虑预测几天的，但到底预测几天，需要理论

！！！波动率的估计

！！！！！！！！！！！申购与赎回作为二元时间序列

！！！！！！！！！！月是不是一个季节项？

!!!!!!!!稳健回归

！！！！！压缩

!!!!!!!!!!!!减去常数（不活跃用户），再取log！！！！！！！！！！


！！！！！！！！！！！对于每一天，识别前后一个月都没有操作的用户！！！！！！！！！！！

!!!!!!!!!!!!diff(log())

!!!!!!!!!!!cox变换，TSA P101

!!!!!!!!!!!!找出outliers

!!!!!!!!!!!!是否要加上季节项

！！！！！！armax模型

！！！！！！！！！！?seasonaldummy


the time series is only affected at time T if it has an additive outlier at T

an innovative outlier at T perturbs all observations on and after T


See Chang et al. (1988) for another approach to classifying the nature of an outlier

When an outlier is found, it can be incorporated into the model, and the outlier-detection procedure can then be repeated with the refined model until no more outliers are found.


对tftobal_amt建模遇到了问题，如果指定d=1,D=1那么趋势是向下的，如果指定d=0,D=1,那么趋势是向上的，差别特别大

?detectAO
?detectIO



用kmeans对用户的聚类还是比较理想的，但是超级土豪还需要手动给筛出来



考虑outlier时间点时哪些用户的贡献大，这些是异常用户



暴力循环得到哪些变量或者哪些用户放到一起MAE最小
svd


ARIMA模型参数的估计：
对AR部分，CSS方法和矩估计是基本上一样的，yule walker方程。MA部分，是用迭代的

stl+arima

季节性的幅度是在变化的

自己的回归基础太差了

数据集AirPassengers挺像的

复鹰(693545461) 16:43:10 
其实我就是把总Purchase和Redeem的时间序列当成一个信号，然后既然是信号就有大尺度衰落和小尺度衰落


3月10日，4月9日，5月5日，6月9日，7月1日，8月1日


第一次提交：用300:427的数据，按照星期做一个平均，分数114.11
第二次提交：用351:427的数据，用STL分解、forecast函数来做，分数112.18
第三次提交：用351:427的数据，用STL分解、forecast函数来做，分男女，分数114.49
第四次提交：用225:427的数据，先用STL分解，然后把趋势项对收益率做回归，得到拟合值，原始数据把这个拟合值去掉，做STL分解，然后forecast预测，然后再加上被收益率解释的部分（未来的收益率需要预测，用的是STL预测），没分男女，102.03
第五次提交：用225:427的数据，用STL、forecast，分男女，稳健,分数110.90
第六次提交：用225:427的数据，用STL、forecast，分男女，前15天不稳健，后15天稳健,分数102.13
第七次提交：用225:427的数据，用STL、forecast，分男女，前15天稳健，后15天不稳健，分数106.47
第八次提交：用225:427的数据，用STL、forecast，分每个小项预测：支付宝购买、银行卡购买。。。。。，然后加和，稳健122.15
第九次提交：和第八次差不多，但是分男女,115.80
第10次提交：和第二次差不多，只是做了个log变换,111.95
第11次提交: 把第8次log变换,119.18
第12次提交：把每天的量除以每天的用户数再做，其余和第8次一样，113.48
第13次提交：和第10次差不多，只是做了log变换后又差分了一下，82.99
第14次提交：和第11次差不多，只不过有的没做log变换，另外用stlm做的,117.49
第15次提交：把第八次，然后把中秋节的量乘以0.9了，这是过拟合啊啊啊啊。。。120.30
第16次提交：推倒前面的，用arima模型来重新做，111.85
第17次提交：用arima模型，用kmeans聚类成大土豪和屌丝，而且对8号和28号进行了修正，分数：107.73
第18次提交：用所有数据，airma模型，对8号和28号修正，分数：115.40
第19次提交：普通天用第八次，8号和18号用第18次的结果，分数：125.76
第20次提交：第8天比第19次提交的保守了些，结果不好了：123.63
第21次提交：用244:427的数据，用STL去季节项，然后用简单线性回归学习残差，分数：120.06
第22次提交：用244:427的数据，用STL去季节项，然后用简单线性回归学习残差，和21次不同的是，把redeem分transfer和consume两项来做的，分数：123.98
第23次提交：在第22次的基础上，学习残差的回归方程修改了一下，并且加上了月初特征，也就是可能每月第1天的purchase特别的多，并且把purchase的补休特征去掉了,120.85



正式：
第一次naive
第八次
第18次